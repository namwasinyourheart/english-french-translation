{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# Basic Packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import TranslationDataset, WMT14\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import random\n",
    "import math\n",
    "import os\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import json\n",
    "\n",
    "SEED = 1\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_fr = spacy.load('fr')\n",
    "spacy_en = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tokenizer when creating the initial data splits filtering\n",
    "def tokenize_fr(text):\n",
    "    \"\"\"\n",
    "    Tokenizes French text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC = Field(tokenize=tokenize_en, init_token='<sos>', eos_token='<eos>', lower=True)\n",
    "TRG = Field(tokenize=tokenize_fr, init_token='<sos>', eos_token='<eos>', lower=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, spacy pretrained tokenizers are used to load the English and German datasets.\n",
    "These spacy models can be used in conjunction with torchtext, allowing the processed data to populate torch tensors and dataset iterators to be created for training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter data to smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrenchTatoeba(TranslationDataset):\n",
    "    \"\"\"English-to-French dataset from Tatoeba\"\"\"\n",
    "\n",
    "    urls = ['https://download.pytorch.org/tutorial/data.zip']\n",
    "    name = 'FrenchTatoeba'\n",
    "    dirname = ''\n",
    "    \n",
    "    @classmethod\n",
    "    def format_data(cls, download_dir, lang1, lang2, reverse=False):\n",
    "        random.seed(1) # Get same split every time\n",
    "        print(\"Reading lines...\")\n",
    "\n",
    "        # Read the file and split into lines\n",
    "        lines = open(os.path.join(download_dir,'data/%s-%s.txt' % (lang1, lang2)), encoding='utf-8').read().strip().split('\\n')\n",
    "\n",
    "        # Split every line into pairs and normalize\n",
    "        pairs = [[s for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "        # Reverse pairs\n",
    "        if reverse:\n",
    "            pairs = [list(reversed(p)) for p in pairs]\n",
    "             \n",
    "        with open(os.path.join(download_dir,'all_data.en'), 'w') as lang1_file, \\\n",
    "                open(os.path.join(download_dir,'all_data.fr'), 'w') as lang2_file:\n",
    "            for p in pairs:\n",
    "                lang1_file.write(p[0] + '\\n')\n",
    "                lang2_file.write(p[1] + '\\n')\n",
    "\n",
    "    @classmethod\n",
    "    def all_data(cls, exts, fields, root='.data',\n",
    "               train='all_data', validation=None, test=None, **kwargs):\n",
    "        \"\"\"Create dataset objects for splits of the Tatoeba dataset.\n",
    "        Arguments:\n",
    "            exts: A tuple containing the extension to path for each language.\n",
    "            fields: A tuple containing the fields that will be used for data\n",
    "                in each language.\n",
    "            root: Root dataset storage directory. Default is '.data'.\n",
    "            train: The prefix of the train data. Default: 'train'.\n",
    "        \"\"\"\n",
    "        \n",
    "        if 'path' not in kwargs:\n",
    "            expected_folder = os.path.join(root, cls.name)\n",
    "            path = expected_folder if os.path.exists(expected_folder) else None\n",
    "        else:\n",
    "            path = kwargs['path']\n",
    "            del kwargs['path']\n",
    "        \n",
    "        if path is None:\n",
    "            path = cls.download(root)\n",
    "        \n",
    "        cls.format_data(path, 'eng', 'fra')\n",
    "\n",
    "        train_data = None if train is None else cls(\n",
    "            os.path.join(path, train), exts, fields, **kwargs)\n",
    "        val_data = None if validation is None else cls(\n",
    "            os.path.join(path, validation), exts, fields, **kwargs)\n",
    "        test_data = None if test is None else cls(\n",
    "            os.path.join(path, test), exts, fields, **kwargs)\n",
    "        \n",
    "        return tuple(d for d in (train_data, val_data, test_data)\n",
    "                     if d is not None)\n",
    "    \n",
    "    @classmethod\n",
    "    def splits(cls, exts, fields, root='.data',\n",
    "               train='train', validation='val', test='test', **kwargs):\n",
    "        \"\"\"Create dataset objects for splits of the Multi30k dataset.\n",
    "        Arguments:\n",
    "            exts: A tuple containing the extension to path for each language.\n",
    "            fields: A tuple containing the fields that will be used for data\n",
    "                in each language.\n",
    "            root: Root dataset storage directory. Default is '.data'.\n",
    "            train: The prefix of the train data. Default: 'train'.\n",
    "            validation: The prefix of the validation data. Default: 'val'.\n",
    "            test: The prefix of the test data. Default: 'test'.\n",
    "            Remaining keyword arguments: Passed to the splits method of\n",
    "                Dataset.\n",
    "        \"\"\"\n",
    "        \n",
    "        if 'path' not in kwargs:\n",
    "            expected_folder = os.path.join(root, cls.name)\n",
    "            path = expected_folder if os.path.exists(expected_folder) else None\n",
    "        else:\n",
    "            path = kwargs['path']\n",
    "            del kwargs['path']\n",
    "            \n",
    "        return super(FrenchTatoeba, cls).splits(\n",
    "            exts, fields, path, root, train, validation, test, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# http://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "#     s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def tokenize_fr(text):\n",
    "    \"\"\"\n",
    "    Tokenizes French text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    text = normalizeString(text)\n",
    "    return [tok.text for tok in spacy_fr.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    text = normalizeString(text)\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 20\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0]) < MAX_LENGTH and \\\n",
    "        len(p[1]) < MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data = FrenchTatoeba.all_data(exts=('.en', '.fr'), \n",
    "                  fields=(SRC, TRG), \n",
    "                  filter_pred=lambda ex: filterPair([ex.src, ex.trg]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in all_data[:10]:\n",
    "    print(e.src, e.trg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = os.path.join('.data', FrenchTatoeba.name)\n",
    "n_examples = len(all_data)\n",
    "idx_array = list(range(n_examples))\n",
    "random.shuffle(idx_array)\n",
    "train_indexs = idx_array[:int(0.8*n_examples)] # 80% training data\n",
    "val_indexs = idx_array[int(0.8*n_examples):int(0.9*n_examples)]\n",
    "test_indexs = idx_array[int(0.9*n_examples):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save train, test, val files for furture experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(download_dir,'train.en'), 'w') as lang1_file, \\\n",
    "        open(os.path.join(download_dir,'train.fr'), 'w') as lang2_file:\n",
    "    for i in train_indexs:\n",
    "        lang1_file.write(' '.join(all_data[i].src) + '\\n')\n",
    "        lang2_file.write(' '.join(all_data[i].trg) + '\\n')\n",
    "\n",
    "with open(os.path.join(download_dir,'val.en'), 'w') as lang1_file, \\\n",
    "        open(os.path.join(download_dir,'val.fr'), 'w') as lang2_file:\n",
    "    for i in val_indexs:\n",
    "        lang1_file.write(' '.join(all_data[i].src) + '\\n')\n",
    "        lang2_file.write(' '.join(all_data[i].trg) + '\\n')\n",
    "\n",
    "with open(os.path.join(download_dir,'test.en'), 'w') as lang1_file, \\\n",
    "        open(os.path.join(download_dir,'test.fr'), 'w') as lang2_file:\n",
    "    for i in test_indexs:\n",
    "        lang1_file.write(' '.join(all_data[i].src) + '\\n')\n",
    "        lang2_file.write(' '.join(all_data[i].trg) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load individual datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = FrenchTatoeba.splits(path='./.data/FrenchTatoeba/', exts=('.en', '.fr'), fields=(SRC, TRG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC.build_vocab(train_data, min_freq=5)\n",
    "TRG.build_vocab(train_data, min_freq=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), batch_size=BATCH_SIZE, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Target distribution analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set size: ', len(train_data))\n",
    "print('Validation set size: ', len(valid_data))\n",
    "print('Testing set size: ', len(test_data))\n",
    "\n",
    "print('Size of English vocabulary: ', len(SRC.vocab))\n",
    "print('Size of French vocabulary: ', len(TRG.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Add in/out of vocab graph for training data vs. validation vs. test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_dual_hist(data, data_src_title, data_tgt_title, title):\n",
    "    data_1 = np.asarray([len(x.src) for x in data])\n",
    "    data_2 = np.asarray([len(x.trg) for x in data])\n",
    "    max_len = max(max(data_1),max(data_2))\n",
    "    bins = range(1, max_len + 1, 1)\n",
    "    plt.hist([data_1, data_2], bins, label=[data_src_title, data_tgt_title], align='left')\n",
    "    plt.legend(loc='upper right')\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.xticks(range(1, max_len))\n",
    "    plt.title(title)\n",
    "    plt.ylabel(\"Number of examples\")\n",
    "    plt.xlabel(\"Example label\")\n",
    "    plt.figure(figsize=(180, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [15, 5]\n",
    "show_dual_hist(train_data,\n",
    "               'English', \n",
    "               'French', \n",
    "               \"Training Sentence Lengths\")\n",
    "show_dual_hist(valid_data,\n",
    "               'English', \n",
    "               'French', \n",
    "               \"Validation Sentence Lengths\")\n",
    "show_dual_hist(test_data,\n",
    "               'English', \n",
    "               'French', \n",
    "               \"Testing Sentence Lengths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_frequency_bar_plot(data, data_title, top_n=100):\n",
    "    objects = sorted(data.freqs, key=data.freqs.get, reverse=True)[0:top_n]\n",
    "    counts = [data.freqs[o] for o in objects]\n",
    "    y_pos = np.arange(len(objects))\n",
    "\n",
    "    plt.barh(y_pos, counts, align='center', alpha=0.5)\n",
    "    plt.yticks(y_pos, objects)\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.xlabel('Count')\n",
    "    plt.title(data_title + \" Top \" + str(top_n) + \" word counts\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [7, 18]\n",
    "word_frequency_bar_plot(SRC.vocab, 'English', top_n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [7, 18]\n",
    "word_frequency_bar_plot(TRG.vocab, 'French', top_n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data for fairseq training. \n",
    "This process creates dictionaries and binary indexes for the data to improve loading times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-preprocess --source-lang en --target-lang fr \\\n",
    "  --trainpref .data/FrenchTatoeba/train --validpref .data/FrenchTatoeba/val --testpref .data/FrenchTatoeba/test \\\n",
    "  --destdir en-fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Building\n",
    "Now we shift our attention to building models. We use the default fairseq training functions from the command line to train these models and save the output log in an experiment diretory (exp). These log files are used to create the graphs for comparisons. \n",
    "Note: To save disk space during the training process (many model checkpoints or best models that will not be used), we pass the `--no-save` flag. After identifying our best configuration, we train that model again, removing this flag to retain the best checkpoint for inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline model (RNN)\n",
    "!python fairseq/train.py ./en-fr/ \\\n",
    "    --arch rnn \\\n",
    "    --encoder-dropout-out 0.2 \\\n",
    "    --encoder-layers 1 \\\n",
    "    --encoder-hidden-size 512 \\\n",
    "    --encoder-embed-dim 256 \\\n",
    "    --decoder-layers 1 \\\n",
    "    --decoder-embed-dim 256 \\\n",
    "    --decoder-hidden-size 512 \\\n",
    "    --decoder-attention False \\\n",
    "    --decoder-dropout-out 0.2 \\\n",
    "    --optimizer adam --lr 0.0001 \\\n",
    "    --lr-shrink 0.5 --max-epoch 100 \\\n",
    "    --seed 1 --log-format json \\\n",
    "    --num-workers 4 \\\n",
    "    --batch-size 512 \\\n",
    "    --weight-decay 0 \\\n",
    "    --no-save --save-dir ./exp/ | tee exp/baseline_rnn.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GRU model\n",
    "!python fairseq/train.py ./en-fr/ \\\n",
    "    --arch gru \\\n",
    "    --encoder-dropout-out 0.2 \\\n",
    "    --encoder-layers 1 \\\n",
    "    --encoder-hidden-size 512 \\\n",
    "    --encoder-embed-dim 256 \\\n",
    "    --decoder-layers 1 \\\n",
    "    --decoder-embed-dim 256 \\\n",
    "    --decoder-hidden-size 512 \\\n",
    "    --decoder-attention False \\\n",
    "    --decoder-dropout-out 0.2 \\\n",
    "    --optimizer adam --lr 0.001 \\\n",
    "    --lr-shrink 0.5 --max-epoch 100 \\\n",
    "    --seed 1 --log-format json \\\n",
    "    --num-workers 4 \\\n",
    "    --batch-size 512 \\\n",
    "    --weight-decay 0 \\\n",
    "    --no-save --save-dir ./exp/ | tee exp/baseline_gru.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train bidirectional GRU model\n",
    "!python fairseq/train.py ./en-fr/ \\\n",
    "    --arch gru \\\n",
    "    --encoder-bidirectional True \\\n",
    "    --encoder-dropout-out 0.2 \\\n",
    "    --encoder-layers 1 \\\n",
    "    --encoder-hidden-size 512 \\\n",
    "    --encoder-embed-dim 256 \\\n",
    "    --decoder-layers 1 \\\n",
    "    --decoder-embed-dim 256 \\\n",
    "    --decoder-hidden-size 512 \\\n",
    "    --decoder-attention False \\\n",
    "    --decoder-dropout-out 0.2 \\\n",
    "    --optimizer adam --lr 0.001 \\\n",
    "    --lr-shrink 0.5 --max-epoch 100 \\\n",
    "    --seed 1 --log-format json \\\n",
    "    --num-workers 4 \\\n",
    "    --batch-size 512 \\\n",
    "    --weight-decay 0 \\\n",
    "    --no-save --save-dir ./exp/ | tee exp/bidirectional_gru.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: We have removed the `--no-save` flag for this last experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Transformer\n",
    "!python fairseq/train.py ./en-fr \\\n",
    "    --arch transformer --no-epoch-checkpoints \\\n",
    "    --dropout 0.2 \\\n",
    "    --encoder-layers 4 \\\n",
    "    --encoder-embed-dim 256 \\\n",
    "    --encoder-attention-heads 4 \\\n",
    "    --encoder-ffn-embed-dim 512 \\\n",
    "    --decoder-layers 4 \\\n",
    "    --decoder-embed-dim 256 \\\n",
    "    --decoder-ffn-embed-dim 256 \\\n",
    "    --decoder-attention-heads 4 \\\n",
    "    --optimizer adam \\\n",
    "    --lr 0.0005 \\\n",
    "    --lr-shrink 0.5 \\\n",
    "    --max-epoch 100 \\\n",
    "    --seed 1 \\\n",
    "    --log-format json \\\n",
    "    --num-workers 4 \\\n",
    "    --batch-size 512 \\\n",
    "    --weight-decay 0 \\\n",
    "    --save-dir ./exp  | tee ./exp/transformer_0.0005_4.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Compare Results\n",
    "Using the logs from training the different models, we can compare their validation loss, compute the BLEU score, and predict on new sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(metrics_dict, title, chart_filter='', y_axis_label=\"\"):\n",
    "    data = pd.DataFrame.from_dict(metrics_dict)\n",
    "    data = data.T\n",
    "    data = data[list(filter(re.compile('.*'+ chart_filter +'.*').match, \n",
    "                            list(data.columns.values)))]\n",
    "    ax = data.astype(float).plot(figsize=(10,6), title=title)\n",
    "    ax.legend(bbox_to_anchor=(1, 1))\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(y_axis_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a json with all experimental results for comparison\n",
    "def load_experiment_results(log_dir):\n",
    "    data = {}\n",
    "    experiment_dir = log_dir\n",
    "    for file in os.listdir(experiment_dir):\n",
    "        if file.endswith(\".log\"):\n",
    "            basename = os.path.splitext(file)[0]\n",
    "            with open(os.path.join(experiment_dir, file)) as f:\n",
    "                for line in f:\n",
    "                    if line[0] == '{':\n",
    "                        info = json.loads(line)\n",
    "                        if int(info[\"epoch\"]) in data:\n",
    "                            new_data = {}\n",
    "                            for k,v in info.items():\n",
    "                                new_data[basename + '_' + k] = v\n",
    "                            data[info[\"epoch\"]].update(new_data)\n",
    "                        else:\n",
    "                            new_data = {}\n",
    "                            for k,v in info.items():\n",
    "                                new_data[basename + '_' + k] = v\n",
    "                            data[info[\"epoch\"]] = new_data\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = load_experiment_results('./exp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(results, \"Model Comparison: Best Models\", \".*_valid_loss\", \"Validation Loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python fairseq/generate.py ./en-fr --path exp/checkpoint_best.pt --remove-bpe  --beam 1 --quiet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
